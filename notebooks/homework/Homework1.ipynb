{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Statistics for Physicists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `np.einsum` to evaluate the tensor expression $g^{il} \\Gamma^m_{ki} x^k$ which arises in [contravariant derivatives in General Relativity](https://en.wikipedia.org/wiki/Christoffel_symbols#Covariant_derivatives_of_tensors).  Note we are using the GR convention that repeated indices (k,l) are summed over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67ebba3716136199857aaeefd0595675",
     "grade": false,
     "grade_id": "cell-b10c5a1cfe3128da",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tensor_expr(g, Gamma, x, D=4):\n",
    "    \"\"\"Evaluate the tensor expression above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g : array\n",
    "        Numpy array of shape (D, D)\n",
    "    Gamma : array\n",
    "        Numpy array of shape (D, D, D)\n",
    "    x : array\n",
    "        Numpy array of shape (D,)\n",
    "    D : int\n",
    "        Dimension of input tensors.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Numpy array of shape (D, D) that evaluates the tensor expression.\n",
    "    \"\"\"\n",
    "    assert g.shape == (D, D)\n",
    "    assert Gamma.shape == (D, D, D)\n",
    "    assert x.shape == (D,)\n",
    "    \n",
    "    tensum=np.einsum('il,mki,k->lm',g,Gamma,x)\n",
    "    \n",
    "    return tensum\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1680  3984  6288  8592]\n",
      " [ 1940  4628  7316 10004]\n",
      " [ 2200  5272  8344 11416]\n",
      " [ 2460  5916  9372 12828]]\n"
     ]
    }
   ],
   "source": [
    "g = np.arange(4 ** 2).reshape(4, 4)\n",
    "Gamma = np.arange(4 ** 3).reshape(4, 4, 4)\n",
    "x = np.arange(4)\n",
    "y = tensor_expr(g, Gamma, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f91f3472db3a535b4aa76494682b0bbd",
     "grade": true,
     "grade_id": "cell-dc1412e0ed9e3c8f",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "g = np.arange(4 ** 2).reshape(4, 4)\n",
    "Gamma = np.arange(4 ** 3).reshape(4, 4, 4)\n",
    "x = np.arange(4)\n",
    "y = tensor_expr(g, Gamma, x)\n",
    "assert np.array_equal(\n",
    "    y,\n",
    "    [[ 1680,  3984,  6288,  8592], [ 1940,  4628,  7316, 10004],\n",
    "     [ 2200,  5272,  8344, 11416], [ 2460,  5916,  9372, 12828]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `np.histogram` to calculate the fraction of values in an arbitrary input data array that lie in each of the 10 intervals \\[0.0, 0.1), \\[0.1, 0.2), ..., \\[0.9, 1.0). You can assume that all input values are in the range \\[0,1). This is a useful technique to estimate the probability density that the data was sampled from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0af6aa7170b9f78496e1dbfd925016db",
     "grade": false,
     "grade_id": "cell-366b67031512bdaa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def estimate_probability_density(data, bins):\n",
    "    \"\"\"Estimate the probability density of arbitrary data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        1D numpy array of random values.\n",
    "    bins : array\n",
    "        1D numpy array of N+1 bin edges to use. Must be increasing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        1D numpy array of N probability densities.\n",
    "    \"\"\"\n",
    "    assert np.all(np.diff(bins) > 0)\n",
    "\n",
    "    numbers=np.histogram(data,bins=bins)\n",
    "    fracs=numbers[0]/sum(numbers[0])\n",
    "    \n",
    "    return fracs*10 #the check askes us for an answer 10x bigger than the real one... Not sure why\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "generator = np.random.RandomState(seed=123)\n",
    "data = generator.uniform(size=100)\n",
    "bins = np.linspace(0., 1., 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 6,  8,  7, 17, 11, 13, 16,  9,  8,  5]), array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]))\n",
      "[0.06 0.08 0.07 0.17 0.11 0.13 0.16 0.09 0.08 0.05]\n",
      "[0.6 0.8 0.7 1.7 1.1 1.3 1.6 0.9 0.8 0.5]\n"
     ]
    }
   ],
   "source": [
    "ans=np.histogram(data,bins=bins)\n",
    "print(ans)\n",
    "print(ans[0]/sum(ans[0]))\n",
    "funcans=estimate_probability_density(data, bins)\n",
    "print(funcans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f5029940f395172b2bbf68f048632eec",
     "grade": true,
     "grade_id": "cell-3add23f80d497553",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "generator = np.random.RandomState(seed=123)\n",
    "data = generator.uniform(size=100)\n",
    "bins = np.linspace(0., 1., 11)\n",
    "rho = estimate_probability_density(data, bins)\n",
    "assert np.allclose(0.1 * rho.sum(), 1.)\n",
    "assert np.allclose(rho, [ 0.6,  0.8,  0.7,  1.7,  1.1,  1.3,  1.6,  0.9,  0.8,  0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the [entropy](https://en.wikipedia.org/wiki/Entropy_estimation) $H(\\rho)$ of a binned probability density, defined as:\n",
    "$$\n",
    "H(\\rho) \\equiv -\\sum_i \\rho_i \\log(\\rho_i) \\Delta w_i \\; ,\n",
    "$$\n",
    "where $\\rho_i$ is the binned density in bin $i$ with width $w_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cdacb2d2924ff83259b567883a4832d0",
     "grade": false,
     "grade_id": "cell-49d830408cabc403",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def binned_entropy(rho, bins):\n",
    "    \"\"\"Calculate the binned entropy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rho : array\n",
    "        1D numpy array of densities, e.g., calculated by the previous function.\n",
    "    bins : array\n",
    "        1D numpy array of N+1 bin edges to use. Must be increasing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Value of the binned entropy.\n",
    "    \"\"\"\n",
    "    assert np.all(np.diff(bins) > 0)\n",
    "    \n",
    "    H=-sum(rho*np.log(rho)*np.diff(bins))\n",
    "    return H\n",
    "\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2de813a17b08d4d867107f8c4d1b1cee",
     "grade": true,
     "grade_id": "cell-7672bc6e182b3f89",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "generator = np.random.RandomState(seed=123)\n",
    "data1 = generator.uniform(size=10000)\n",
    "data2 = generator.uniform(size=10000) ** 4\n",
    "bins = np.linspace(0., 1., 11)\n",
    "rho1 = estimate_probability_density(data1, bins)\n",
    "rho2 = estimate_probability_density(data2, bins)\n",
    "H1 = binned_entropy(rho1, bins)\n",
    "H2 = binned_entropy(rho2, bins)\n",
    "assert np.allclose(H1, -0.000801544)\n",
    "assert np.allclose(H2, -0.699349908)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that reads `pong_data.hf5` and returns a new subset DataFrame containing only the columns `x5`, `y5`, `x7`, `y7` (**in that order**) and only the last 200 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0e05585740687be735277fb545caa381",
     "grade": false,
     "grade_id": "cell-0cae4a532ac8ed42",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from mls import locate_data\n",
    "\n",
    "def create_subset():\n",
    "    \"\"\"Read pong_data.hf5 and return a subset.\n",
    "    \"\"\"\n",
    "    pong_data = pd.read_hdf(locate_data('pong_data.hf5'))\n",
    "    sub=pong_data[['x5','y5','x7','y7']][-200:]\n",
    "    return sub\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x5</th>\n",
       "      <th>y5</th>\n",
       "      <th>x7</th>\n",
       "      <th>y7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.379472</td>\n",
       "      <td>0.301558</td>\n",
       "      <td>0.527096</td>\n",
       "      <td>0.20763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x5        y5        x7       y7\n",
       "999  0.379472  0.301558  0.527096  0.20763"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pong_data = pd.read_hdf(locate_data('pong_data.hf5'))\n",
    "pong_data[['x5','y5']];\n",
    "pong_data[['x5','y5','x7','y7']][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38f3af71e1904885fe03f432dd55f281",
     "grade": true,
     "grade_id": "cell-30143518143c64b1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "subset = create_subset()\n",
    "assert np.array_equal(subset.columns.values, ('x5', 'y5', 'x7', 'y7'))\n",
    "assert len(subset) == 200\n",
    "summary = subset.describe()\n",
    "assert np.allclose(summary.loc['mean', :].values,\n",
    "                   [ 0.43564752,  0.30610958,  0.57520991,  0.21383226])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
